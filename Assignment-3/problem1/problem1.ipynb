{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f780824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1: Logistic Regression Model\n",
    "# Classification of Cancer Dataset (Malignant vs. Benign)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature scaling and standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Part (i): Build a logistic regression model with all 30 features\n",
    "print(\"\\n--- Part (i): Logistic Regression with all features ---\")\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Malignant', 'Benign'], yticklabels=['Malignant', 'Benign'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Logistic Regression (No Weight Penalty)')\n",
    "plt.savefig('confusion_matrix_logreg.png')\n",
    "plt.show()\n",
    "\n",
    "# Part (ii): Add weight penalty (L2 regularization) and repeat training\n",
    "print(\"\\n--- Part (ii): Logistic Regression with weight penalty (L2 regularization) ---\")\n",
    "\n",
    "# Create and train the logistic regression model with L2 regularization\n",
    "# Note: Default regularization in LogisticRegression is L2 ('ridge')\n",
    "# We'll set the C parameter to control regularization strength (lower C = stronger regularization)\n",
    "logreg_l2 = LogisticRegression(random_state=42, max_iter=1000, C=0.1)\n",
    "logreg_l2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_l2 = logreg_l2.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "precision_l2 = precision_score(y_test, y_pred_l2)\n",
    "recall_l2 = recall_score(y_test, y_pred_l2)\n",
    "f1_l2 = f1_score(y_test, y_pred_l2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy (L2): {accuracy_l2:.4f}\")\n",
    "print(f\"Precision (L2): {precision_l2:.4f}\")\n",
    "print(f\"Recall (L2): {recall_l2:.4f}\")\n",
    "print(f\"F1 Score (L2): {f1_l2:.4f}\")\n",
    "print(\"\\nClassification Report (L2):\")\n",
    "print(classification_report(y_test, y_pred_l2, target_names=['Malignant', 'Benign']))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_l2 = confusion_matrix(y_test, y_pred_l2)\n",
    "sns.heatmap(cm_l2, annot=True, fmt='d', cmap='Blues', xticklabels=['Malignant', 'Benign'], yticklabels=['Malignant', 'Benign'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Logistic Regression (With L2 Regularization)')\n",
    "plt.savefig('confusion_matrix_logreg_l2.png')\n",
    "plt.show()\n",
    "\n",
    "# Compare the two models\n",
    "print(\"\\n--- Comparison: No Regularization vs. L2 Regularization ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f} vs {accuracy_l2:.4f}\")\n",
    "print(f\"Precision: {precision:.4f} vs {precision_l2:.4f}\")\n",
    "print(f\"Recall: {recall:.4f} vs {recall_l2:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f} vs {f1_l2:.4f}\")\n",
    "\n",
    "# Plot feature importance for both models\n",
    "plt.figure(figsize=(14, 8))\n",
    "feature_names = cancer.feature_names\n",
    "\n",
    "# For the model without regularization\n",
    "plt.subplot(1, 2, 1)\n",
    "coef = logreg.coef_[0]\n",
    "indices = np.argsort(np.abs(coef))[::-1]\n",
    "plt.barh(range(len(indices)), coef[indices])\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.title('Feature Importance - No Regularization')\n",
    "plt.xlabel('Coefficient Value')\n",
    "\n",
    "# For the model with L2 regularization\n",
    "plt.subplot(1, 2, 2)\n",
    "coef_l2 = logreg_l2.coef_[0]\n",
    "indices_l2 = np.argsort(np.abs(coef_l2))[::-1]\n",
    "plt.barh(range(len(indices_l2)), coef_l2[indices_l2])\n",
    "plt.yticks(range(len(indices_l2)), [feature_names[i] for i in indices_l2])\n",
    "plt.title('Feature Importance - L2 Regularization')\n",
    "plt.xlabel('Coefficient Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# Display a sample of the dataset\n",
    "print(\"\\nSample of the dataset:\")\n",
    "df_cancer = pd.DataFrame(X, columns=cancer.feature_names)\n",
    "df_cancer['target'] = y\n",
    "df_cancer['diagnosis'] = ['Malignant' if t == 0 else 'Benign' for t in y]\n",
    "print(df_cancer.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
